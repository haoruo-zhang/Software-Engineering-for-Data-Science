{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from src.utils import calculate_distance\n",
    "from src.utils import calculate_bounding_box_area\n",
    "from src.utils import determine_side\n",
    "from src.utils import plot_dynamic_chart\n",
    "from src.utils import calculate_angle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对视频按照深蹲次数进行切割\n",
    "# Load YOLOv8 pose estimation model\n",
    "model = YOLO('yolov8l-pose.pt')\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture('sample6.mp4')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# 定义视频输出格式\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('trimmed_output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# 变量来跟踪深蹲的状态\n",
    "initial_shoulder_pos = None\n",
    "squat_start = False\n",
    "segment_count = 0\n",
    "current_video_writer = None\n",
    "\n",
    "threshold_down = 15  # 用于检测肩膀显著下移的阈值（单位：像素）\n",
    "threshold_up = 10   # 用于检测肩膀回到初始位置的阈值\n",
    "threshold_horizontal = 10\n",
    "\n",
    "extra_frames = 10   # 深蹲结束后，延长的帧数\n",
    "extra_frame_counter = 0\n",
    "\n",
    "# 遍历视频的每一帧\n",
    "frame_count = 0\n",
    "results = model('sample6.mp4')  # 使用 YOLO 模型进行姿态检测\n",
    "\n",
    "for result in results:\n",
    "    frame_count += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 获取关键点\n",
    "    all_keypoints = result.keypoints.data  # 所有关键点\n",
    "\n",
    "    max_area = 0\n",
    "    largest_person = None\n",
    "\n",
    "    # 找到检测到的最大目标\n",
    "    for keypoints in all_keypoints:\n",
    "        area = calculate_bounding_box_area(keypoints)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            largest_person = keypoints\n",
    "\n",
    "    if largest_person is not None:\n",
    "        # 获取左肩膀的坐标\n",
    "        left_shoulder = largest_person[5][:2].cpu().numpy()\n",
    "        left_hip = largest_person[11][:2].cpu().numpy()\n",
    "        left_knee = largest_person[13][:2].cpu().numpy()\n",
    "        left_ankle = largest_person[15][:2].cpu().numpy()\n",
    "\n",
    "        right_shoulder = largest_person[6][:2].cpu().numpy()\n",
    "        right_hip = largest_person[12][:2].cpu().numpy()\n",
    "        right_knee = largest_person[14][:2].cpu().numpy()\n",
    "        right_ankle = largest_person[16][:2].cpu().numpy()\n",
    "\n",
    "        side, shoulder, hip, knee, ankle = determine_side(side, left_shoulder, left_hip, left_knee, left_ankle, right_shoulder, right_hip, right_knee, right_ankle)\n",
    "        if initial_shoulder_pos is None:\n",
    "            # 初始化肩膀的初始位置\n",
    "            initial_shoulder_pos = shoulder\n",
    "            continue\n",
    "\n",
    "        # 计算肩膀的位移（Y 轴）\n",
    "        shoulder_vertical_movement = shoulder[1] - initial_shoulder_pos[1]\n",
    "        shoulder_horizontal_movement = abs(shoulder[0] - initial_shoulder_pos[0])\n",
    "        # 检测深蹲开始：肩膀显著向下移动\n",
    "        if shoulder_vertical_movement > threshold_down and not squat_start and shoulder_horizontal_movement<threshold_horizontal:\n",
    "            squat_start = True\n",
    "            extra_frame_counter = 0  # 重置延长帧计数器\n",
    "            segment_count += 1\n",
    "            # 创建一个新的视频文件来保存这一段\n",
    "            current_video_writer = cv2.VideoWriter(f'squat_segment_{segment_count}.mp4', fourcc, fps, (width, height))\n",
    "            print(f\"Starting squat segment {segment_count}\")\n",
    "\n",
    "        # 检测深蹲结束：肩膀回到接近初始位置\n",
    "        elif shoulder_vertical_movement < threshold_up and squat_start:\n",
    "            if extra_frame_counter == 0:\n",
    "                print(f\"Ending squat segment {segment_count}, but continuing for {extra_frames} more frames.\")\n",
    "            extra_frame_counter += 1\n",
    "            if extra_frame_counter >= extra_frames:\n",
    "                squat_start = False\n",
    "                # 关闭当前视频片段保存\n",
    "                if current_video_writer is not None:\n",
    "                    current_video_writer.release()\n",
    "                    current_video_writer = None\n",
    "                print(f\"Completely ended squat segment {segment_count}\")\n",
    "\n",
    "        # 写入帧到当前视频段\n",
    "        if squat_start or (extra_frame_counter > 0 and extra_frame_counter <= extra_frames):\n",
    "            if current_video_writer is not None:\n",
    "                current_video_writer.write(frame)\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "if current_video_writer is not None:\n",
    "    current_video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 106.3ms\n",
      "video 1/1 (frame 2/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.0ms\n",
      "video 1/1 (frame 3/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 22.7ms\n",
      "video 1/1 (frame 4/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 32.8ms\n",
      "video 1/1 (frame 5/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 29.4ms\n",
      "video 1/1 (frame 6/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 27.0ms\n",
      "video 1/1 (frame 7/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 18.2ms\n",
      "video 1/1 (frame 8/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 16.8ms\n",
      "video 1/1 (frame 9/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.4ms\n",
      "video 1/1 (frame 10/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 30.9ms\n",
      "video 1/1 (frame 11/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 26.2ms\n",
      "video 1/1 (frame 12/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 15.6ms\n",
      "video 1/1 (frame 13/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 25.1ms\n",
      "video 1/1 (frame 14/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 31.5ms\n",
      "video 1/1 (frame 15/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 15.6ms\n",
      "video 1/1 (frame 16/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 19.3ms\n",
      "video 1/1 (frame 17/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.9ms\n",
      "video 1/1 (frame 18/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 28.9ms\n",
      "video 1/1 (frame 19/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 15.5ms\n",
      "video 1/1 (frame 20/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 21.4ms\n",
      "video 1/1 (frame 21/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.4ms\n",
      "video 1/1 (frame 22/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 25.9ms\n",
      "video 1/1 (frame 23/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 26.2ms\n",
      "video 1/1 (frame 24/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 25.9ms\n",
      "video 1/1 (frame 25/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.2ms\n",
      "video 1/1 (frame 26/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 27.1ms\n",
      "video 1/1 (frame 27/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.7ms\n",
      "video 1/1 (frame 28/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.8ms\n",
      "video 1/1 (frame 29/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 29.8ms\n",
      "video 1/1 (frame 30/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 16.1ms\n",
      "video 1/1 (frame 31/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 27.7ms\n",
      "video 1/1 (frame 32/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.2ms\n",
      "video 1/1 (frame 33/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 27.7ms\n",
      "video 1/1 (frame 34/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 17.4ms\n",
      "video 1/1 (frame 35/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 25.6ms\n",
      "video 1/1 (frame 36/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.7ms\n",
      "video 1/1 (frame 37/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 32.4ms\n",
      "video 1/1 (frame 38/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 19.5ms\n",
      "video 1/1 (frame 39/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 17.8ms\n",
      "video 1/1 (frame 40/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 25.4ms\n",
      "video 1/1 (frame 41/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 20.1ms\n",
      "video 1/1 (frame 42/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 18.0ms\n",
      "video 1/1 (frame 43/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 20.9ms\n",
      "video 1/1 (frame 44/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 32.4ms\n",
      "video 1/1 (frame 45/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 27.0ms\n",
      "video 1/1 (frame 46/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 22.8ms\n",
      "video 1/1 (frame 47/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 18.8ms\n",
      "video 1/1 (frame 48/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.4ms\n",
      "video 1/1 (frame 49/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 19.3ms\n",
      "video 1/1 (frame 50/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 17.0ms\n",
      "video 1/1 (frame 51/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.6ms\n",
      "video 1/1 (frame 52/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 20.9ms\n",
      "video 1/1 (frame 53/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.3ms\n",
      "video 1/1 (frame 54/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.6ms\n",
      "video 1/1 (frame 55/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.9ms\n",
      "video 1/1 (frame 56/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 29.5ms\n",
      "video 1/1 (frame 57/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 27.0ms\n",
      "video 1/1 (frame 58/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.7ms\n",
      "video 1/1 (frame 59/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.5ms\n",
      "video 1/1 (frame 60/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 27.7ms\n",
      "video 1/1 (frame 61/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.5ms\n",
      "video 1/1 (frame 62/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.1ms\n",
      "video 1/1 (frame 63/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.2ms\n",
      "video 1/1 (frame 64/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 20.4ms\n",
      "video 1/1 (frame 65/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 15.7ms\n",
      "video 1/1 (frame 66/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 26.3ms\n",
      "video 1/1 (frame 67/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 17.7ms\n",
      "video 1/1 (frame 68/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 25.9ms\n",
      "video 1/1 (frame 69/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.6ms\n",
      "video 1/1 (frame 70/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.5ms\n",
      "video 1/1 (frame 71/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 27.6ms\n",
      "video 1/1 (frame 72/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.7ms\n",
      "video 1/1 (frame 73/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.9ms\n",
      "video 1/1 (frame 74/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.5ms\n",
      "video 1/1 (frame 75/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.7ms\n",
      "video 1/1 (frame 76/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 24.4ms\n",
      "video 1/1 (frame 77/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 25.9ms\n",
      "video 1/1 (frame 78/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 27.8ms\n",
      "video 1/1 (frame 79/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 14.6ms\n",
      "video 1/1 (frame 80/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 23.7ms\n",
      "video 1/1 (frame 81/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 31.0ms\n",
      "video 1/1 (frame 82/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 21.5ms\n",
      "video 1/1 (frame 83/83) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_1.mp4: 640x384 1 person, 28.6ms\n",
      "Speed: 0.7ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Output video saved as output_with_plots.mp4\n"
     ]
    }
   ],
   "source": [
    "# 加载 YOLOv8 姿态估计模型\n",
    "model = YOLO('yolov8l-pose.pt')\n",
    "file_index = 1\n",
    "file_name = 'squat_segment_{}.mp4'.format(file_index)\n",
    "output_file = 'output_with_plots_{}.mp4'.format(file_index)\n",
    "\n",
    "# 打开深蹲视频\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_width = frame_width + 500  # 增加500px的宽度用于图表\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (output_width, frame_height))\n",
    "\n",
    "time_values = []\n",
    "speed_values = []\n",
    "knee_angles = [] \n",
    "hip_angles = []  \n",
    "frame_number = 0\n",
    "previous_position = None\n",
    "side = None\n",
    "\n",
    "results = model(file_name)\n",
    "\n",
    "for result in results:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    all_keypoints = result.keypoints.data  # 所有关键点\n",
    "\n",
    "    max_area = 0\n",
    "    largest_person = None\n",
    "\n",
    "    for keypoints in all_keypoints:\n",
    "        area = calculate_bounding_box_area(keypoints)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            largest_person = keypoints\n",
    "\n",
    "    if largest_person is not None:\n",
    "        left_shoulder = largest_person[5][:2].cpu().numpy()\n",
    "        left_hip = largest_person[11][:2].cpu().numpy()\n",
    "        left_knee = largest_person[13][:2].cpu().numpy()\n",
    "        left_ankle = largest_person[15][:2].cpu().numpy()\n",
    "\n",
    "        right_shoulder = largest_person[6][:2].cpu().numpy()\n",
    "        right_hip = largest_person[12][:2].cpu().numpy()\n",
    "        right_knee = largest_person[14][:2].cpu().numpy()\n",
    "        right_ankle = largest_person[16][:2].cpu().numpy()\n",
    "\n",
    "        side, shoulder, hip, knee, ankle = determine_side(side, left_shoulder, left_hip, left_knee, left_ankle, right_shoulder, right_hip, right_knee, right_ankle)\n",
    "\n",
    "        if previous_position is None:\n",
    "            previous_position = (shoulder + hip) / 2\n",
    "            frame_number += 1\n",
    "            continue\n",
    "\n",
    "        knee_angle = calculate_angle(hip, knee, ankle)\n",
    "        knee_angles.append(knee_angle)\n",
    "\n",
    "        hip_angle = calculate_angle(shoulder, hip, knee)\n",
    "        hip_angles.append(hip_angle)\n",
    "        \n",
    "        avg_position = (shoulder + hip) / 2\n",
    "        vertical_movement = previous_position[1] - avg_position[1]\n",
    "        frame_time = frame_number / fps\n",
    "        speed = vertical_movement * fps\n",
    "        time_values.append(frame_time)\n",
    "        speed_values.append(speed)\n",
    "\n",
    "        previous_position = avg_position\n",
    "\n",
    "        distance1 = calculate_distance(hip, knee)\n",
    "        distance2 = calculate_distance(knee, ankle)\n",
    "        distance3 = calculate_distance(shoulder, hip)\n",
    "        distance4 = distance1 + distance2 \n",
    "        ratio1 = distance1 / distance2\n",
    "        ratio2 = distance3 / distance4\n",
    "\n",
    "        annotated_frame = result.plot()\n",
    "        cv2.putText(annotated_frame, f\"Femur Length: {distance1:.2f} px\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Tibia Length: {distance2:.2f} px\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Torso Length: {distance3:.2f} px\", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Leg Length: {distance4:.2f} px\", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Femur/Tibia: {ratio1:.2f}\", (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Torso/Leg: {ratio2:.2f}\", (50, 300), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "\n",
    "        plot_image = plot_dynamic_chart(time_values, speed_values, knee_angles, hip_angles)\n",
    "        plot_image_resized = cv2.resize(plot_image, (500, frame_height))\n",
    "\n",
    "        combined_frame = np.hstack((annotated_frame, plot_image_resized))\n",
    "        out.write(combined_frame)\n",
    "\n",
    "    frame_number += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Output video saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 49.9ms\n",
      "video 1/1 (frame 2/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 33.0ms\n",
      "video 1/1 (frame 3/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 34.4ms\n",
      "video 1/1 (frame 4/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 34.3ms\n",
      "video 1/1 (frame 5/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 17.4ms\n",
      "video 1/1 (frame 6/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 18.3ms\n",
      "video 1/1 (frame 7/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 25.2ms\n",
      "video 1/1 (frame 8/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.8ms\n",
      "video 1/1 (frame 9/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 32.1ms\n",
      "video 1/1 (frame 10/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 26.9ms\n",
      "video 1/1 (frame 11/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 15.8ms\n",
      "video 1/1 (frame 12/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 34.1ms\n",
      "video 1/1 (frame 13/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 32.6ms\n",
      "video 1/1 (frame 14/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 18.1ms\n",
      "video 1/1 (frame 15/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 16.8ms\n",
      "video 1/1 (frame 16/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 33.2ms\n",
      "video 1/1 (frame 17/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.6ms\n",
      "video 1/1 (frame 18/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.7ms\n",
      "video 1/1 (frame 19/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 18.5ms\n",
      "video 1/1 (frame 20/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 22.9ms\n",
      "video 1/1 (frame 21/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 22.9ms\n",
      "video 1/1 (frame 22/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 16.7ms\n",
      "video 1/1 (frame 23/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 18.8ms\n",
      "video 1/1 (frame 24/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.4ms\n",
      "video 1/1 (frame 25/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 29.9ms\n",
      "video 1/1 (frame 26/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.5ms\n",
      "video 1/1 (frame 27/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 22.7ms\n",
      "video 1/1 (frame 28/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 20.4ms\n",
      "video 1/1 (frame 29/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 27.9ms\n",
      "video 1/1 (frame 30/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 14.1ms\n",
      "video 1/1 (frame 31/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 17.9ms\n",
      "video 1/1 (frame 32/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 26.0ms\n",
      "video 1/1 (frame 33/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.3ms\n",
      "video 1/1 (frame 34/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 21.8ms\n",
      "video 1/1 (frame 35/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 25.0ms\n",
      "video 1/1 (frame 36/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.9ms\n",
      "video 1/1 (frame 37/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 25.2ms\n",
      "video 1/1 (frame 38/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 14.5ms\n",
      "video 1/1 (frame 39/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.0ms\n",
      "video 1/1 (frame 40/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 28.0ms\n",
      "video 1/1 (frame 41/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.3ms\n",
      "video 1/1 (frame 42/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 27.5ms\n",
      "video 1/1 (frame 43/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.7ms\n",
      "video 1/1 (frame 44/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 22.2ms\n",
      "video 1/1 (frame 45/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 30.4ms\n",
      "video 1/1 (frame 46/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 18.1ms\n",
      "video 1/1 (frame 47/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.4ms\n",
      "video 1/1 (frame 48/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 2 persons, 23.7ms\n",
      "video 1/1 (frame 49/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 29.1ms\n",
      "video 1/1 (frame 50/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.4ms\n",
      "video 1/1 (frame 51/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 27.2ms\n",
      "video 1/1 (frame 52/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.6ms\n",
      "video 1/1 (frame 53/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 20.5ms\n",
      "video 1/1 (frame 54/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.0ms\n",
      "video 1/1 (frame 55/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.7ms\n",
      "video 1/1 (frame 56/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.2ms\n",
      "video 1/1 (frame 57/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.9ms\n",
      "video 1/1 (frame 58/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.9ms\n",
      "video 1/1 (frame 59/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 20.2ms\n",
      "video 1/1 (frame 60/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.4ms\n",
      "video 1/1 (frame 61/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 30.6ms\n",
      "video 1/1 (frame 62/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 25.8ms\n",
      "video 1/1 (frame 63/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.2ms\n",
      "video 1/1 (frame 64/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 28.7ms\n",
      "video 1/1 (frame 65/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.7ms\n",
      "video 1/1 (frame 66/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.2ms\n",
      "video 1/1 (frame 67/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.2ms\n",
      "video 1/1 (frame 68/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.1ms\n",
      "video 1/1 (frame 69/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 27.6ms\n",
      "video 1/1 (frame 70/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.9ms\n",
      "video 1/1 (frame 71/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 20.2ms\n",
      "video 1/1 (frame 72/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 31.5ms\n",
      "video 1/1 (frame 73/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 21.1ms\n",
      "video 1/1 (frame 74/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 16.8ms\n",
      "video 1/1 (frame 75/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.7ms\n",
      "video 1/1 (frame 76/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.2ms\n",
      "video 1/1 (frame 77/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.4ms\n",
      "video 1/1 (frame 78/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 16.7ms\n",
      "video 1/1 (frame 79/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 26.1ms\n",
      "video 1/1 (frame 80/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 18.1ms\n",
      "video 1/1 (frame 81/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 25.4ms\n",
      "video 1/1 (frame 82/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 24.2ms\n",
      "video 1/1 (frame 83/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.3ms\n",
      "video 1/1 (frame 84/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 28.1ms\n",
      "video 1/1 (frame 85/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.0ms\n",
      "video 1/1 (frame 86/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 20.2ms\n",
      "video 1/1 (frame 87/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 23.3ms\n",
      "video 1/1 (frame 88/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 29.2ms\n",
      "video 1/1 (frame 89/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 25.6ms\n",
      "video 1/1 (frame 90/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 28.2ms\n",
      "video 1/1 (frame 91/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 15.0ms\n",
      "video 1/1 (frame 92/92) d:\\software-engineer\\TITAN TRACK\\Software-Engineering-for-Data-Science\\squat_segment_2.mp4: 640x384 1 person, 26.5ms\n",
      "Speed: 1.3ms preprocess, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Output video saved as output_with_plots_2.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 加载 YOLOv8 姿态估计模型\n",
    "model = YOLO('yolov8l-pose.pt')\n",
    "file_index = 2\n",
    "file_name = 'squat_segment_{}.mp4'.format(file_index)\n",
    "output_file = 'output_with_plots_{}.mp4'.format(file_index)\n",
    "\n",
    "# 打开深蹲视频\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_width = 2*frame_width + 500  # 增加1000px的宽度用于两个额外的部分（关节轨迹和图表）\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (output_width, frame_height))\n",
    "\n",
    "# 初始化变量\n",
    "time_values = []\n",
    "speed_values = []\n",
    "knee_angles = []\n",
    "hip_angles = []\n",
    "frame_number = 0\n",
    "previous_position = None\n",
    "side = None\n",
    "\n",
    "# 运行YOLO模型进行姿态估计\n",
    "results = model(file_name)\n",
    "\n",
    "# 循环处理每一帧\n",
    "for result in results:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 获取所有关键点\n",
    "    all_keypoints = result.keypoints.data\n",
    "    max_area = 0\n",
    "    largest_person = None\n",
    "\n",
    "    # 查找最大面积的人物\n",
    "    for keypoints in all_keypoints:\n",
    "        area = calculate_bounding_box_area(keypoints)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            largest_person = keypoints\n",
    "\n",
    "    if largest_person is not None:\n",
    "        # 获取左侧和右侧的关键点坐标\n",
    "        left_shoulder = largest_person[5][:2].cpu().numpy()\n",
    "        left_hip = largest_person[11][:2].cpu().numpy()\n",
    "        left_knee = largest_person[13][:2].cpu().numpy()\n",
    "        left_ankle = largest_person[15][:2].cpu().numpy()\n",
    "\n",
    "        right_shoulder = largest_person[6][:2].cpu().numpy()\n",
    "        right_hip = largest_person[12][:2].cpu().numpy()\n",
    "        right_knee = largest_person[14][:2].cpu().numpy()\n",
    "        right_ankle = largest_person[16][:2].cpu().numpy()\n",
    "\n",
    "        # 确定侧面（左侧或右侧）并更新相关关键点\n",
    "        side, shoulder, hip, knee, ankle = determine_side(side, left_shoulder, left_hip, left_knee, left_ankle, right_shoulder, right_hip, right_knee, right_ankle)\n",
    "\n",
    "        # 如果是第一帧，初始化previous_position\n",
    "        if previous_position is None:\n",
    "            previous_position = (shoulder + hip) / 2\n",
    "            frame_number += 1\n",
    "            continue\n",
    "\n",
    "        # 计算膝盖角度和髋部角度\n",
    "        knee_angle = calculate_angle(hip, knee, ankle)\n",
    "        knee_angles.append(knee_angle)\n",
    "\n",
    "        hip_angle = calculate_angle(shoulder, hip, knee)\n",
    "        hip_angles.append(hip_angle)\n",
    "\n",
    "        # 计算速度\n",
    "        avg_position = (shoulder + hip) / 2\n",
    "        vertical_movement = previous_position[1] - avg_position[1]\n",
    "        frame_time = frame_number / fps\n",
    "        speed = vertical_movement * fps\n",
    "        time_values.append(frame_time)\n",
    "        speed_values.append(speed)\n",
    "\n",
    "        previous_position = avg_position\n",
    "\n",
    "        # 计算关键点之间的距离\n",
    "        distance1 = calculate_distance(hip, knee)\n",
    "        distance2 = calculate_distance(knee, ankle)\n",
    "        distance3 = calculate_distance(shoulder, hip)\n",
    "        distance4 = distance1 + distance2\n",
    "        ratio1 = distance1 / distance2\n",
    "        ratio2 = distance3 / distance4\n",
    "\n",
    "        # 在原始视频帧上添加注释\n",
    "        annotated_frame = result.plot()\n",
    "        cv2.putText(annotated_frame, f\"Femur Length: {distance1:.2f} px\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Tibia Length: {distance2:.2f} px\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Torso Length: {distance3:.2f} px\", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Leg Length: {distance4:.2f} px\", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Femur/Tibia: {ratio1:.2f}\", (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "        cv2.putText(annotated_frame, f\"Torso/Leg: {ratio2:.2f}\", (50, 300), cv2.FONT_HERSHEY_SIMPLEX, 1, (238, 173, 14), 2)\n",
    "\n",
    "        # 创建用于绘制关键点运动的帧\n",
    "        keypoints_frame = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)  # 空白帧，用于绘制关键点\n",
    "        cv2.circle(keypoints_frame, tuple(shoulder.astype(int)), 5, (0, 255, 0), -1)  # 肩膀\n",
    "        cv2.circle(keypoints_frame, tuple(hip.astype(int)), 5, (0, 255, 0), -1)       # 髋部\n",
    "        cv2.circle(keypoints_frame, tuple(knee.astype(int)), 5, (0, 255, 0), -1)      # 膝盖\n",
    "        cv2.circle(keypoints_frame, tuple(ankle.astype(int)), 5, (0, 255, 0), -1)     # 脚踝\n",
    "\n",
    "        # 绘制关节之间的连线\n",
    "        cv2.line(keypoints_frame, tuple(shoulder.astype(int)), tuple(hip.astype(int)), (255, 0, 0), 2)\n",
    "        cv2.line(keypoints_frame, tuple(hip.astype(int)), tuple(knee.astype(int)), (255, 0, 0), 2)\n",
    "        cv2.line(keypoints_frame, tuple(knee.astype(int)), tuple(ankle.astype(int)), (255, 0, 0), 2)\n",
    "\n",
    "        # 绘制动态图表\n",
    "        plot_image = plot_dynamic_chart(time_values, speed_values, knee_angles, hip_angles)\n",
    "        plot_image_resized = cv2.resize(plot_image, (500, frame_height))  # 调整图表大小\n",
    "\n",
    "        # 将原始视频帧、keypoints_frame（关键点帧）和图表帧拼接在一起\n",
    "        combined_frame = np.hstack((keypoints_frame, annotated_frame, plot_image_resized))\n",
    "        out.write(combined_frame)\n",
    "\n",
    "    frame_number += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Output video saved as {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
