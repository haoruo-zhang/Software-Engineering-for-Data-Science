{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#识别离心阶段\n",
    "\n",
    "# 加载 YOLOv8 姿态估计模型\n",
    "model = YOLO('yolov8l-pose.pt')\n",
    "file_name = 'squat_segment_1.mp4'\n",
    "# 打开深蹲的分段视频\n",
    "cap = cv2.VideoCapture(file_name)  # 使用你的深蹲分段视频路径\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))  # 获取帧率\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# 定义视频输出格式\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# 定义变量\n",
    "previous_position = None\n",
    "tracking_ascending = False  # 标记是否进入向心阶段\n",
    "movement_threshold = 8  # 设置检测向上移动的差阈值为 15 像素\n",
    "video_out = None  # 用于保存剪辑的视频\n",
    "\n",
    "frame_number = 0\n",
    "\n",
    "# 遍历视频的每一帧\n",
    "results = model(file_name)  # 使用 YOLO 模型进行姿态检测\n",
    "\n",
    "for result in results:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 获取关键点\n",
    "    all_keypoints = result.keypoints.data  # 所有关键点\n",
    "\n",
    "    max_area = 0\n",
    "    largest_person = None\n",
    "\n",
    "    # 找到检测到的最大目标\n",
    "    for keypoints in all_keypoints:\n",
    "        area = calculate_bounding_box_area(keypoints)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            largest_person = keypoints\n",
    "\n",
    "    if largest_person is not None:\n",
    "        # 计算左肩膀、左髋关节、左膝盖的坐标平均值，作为检测的垂直位置\n",
    "        avg_position = (largest_person[11][:2].cpu().numpy() +  # 左髋关节\n",
    "                        largest_person[5][:2].cpu().numpy()) / 2  # 左肩膀\n",
    "\n",
    "        # 如果没有初始化上一帧的位置，先初始化\n",
    "        if previous_position is None:\n",
    "            previous_position = avg_position\n",
    "            frame_number += 1\n",
    "            continue\n",
    "\n",
    "        # 计算平均坐标的垂直移动量（Y 轴）\n",
    "        vertical_movement = previous_position[1] - avg_position[1]  # 如果位置上升，垂直位移为正\n",
    "\n",
    "        # 检测向心阶段的开始\n",
    "        if not tracking_ascending and vertical_movement > movement_threshold:\n",
    "            # 向心阶段开始\n",
    "            print(f\"Detected start of concentric phase at frame {frame_number}.\")\n",
    "            tracking_ascending = True\n",
    "            # 开始保存视频\n",
    "            video_out = cv2.VideoWriter(f'concentric_segment_{frame_number}.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "        # 如果进入了向心阶段，保存视频\n",
    "        if tracking_ascending:\n",
    "            video_out.write(frame)\n",
    "\n",
    "            \n",
    "\n",
    "        # 更新上一帧的位置\n",
    "        previous_position = avg_position\n",
    "\n",
    "    frame_number += 1\n",
    "if video_out is not None:\n",
    "    video_out.release()  # 结束视频片段保存\n",
    "# 释放资源\n",
    "cap.release()\n",
    "if video_out is not None:\n",
    "    video_out.release()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
